{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import empty\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import csv\n",
    "from pandas import read_csv\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create csv file to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining file name\n",
    "today = date.today()\n",
    "fileName = 'scraping_{}.csv'.format(today.strftime(\"%b-%d-%Y\"))\n",
    "\n",
    "# create csv file\n",
    "csv_file = open(fileName, 'w', encoding=\"UTF-8\", newline=\"\")\n",
    "writer = csv.writer(csv_file, delimiter = ';')\n",
    "\n",
    "# write header names\n",
    "writer.writerow(['url', 'title', 'views', 'likes', 'comments', 'comments_likes'])\n",
    "\n",
    "# dict for put the info\n",
    "youtube_info = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import YouTube links (in 'file_links' put the file path with the links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read youtube links\n",
    "file_links ='needed_files\\youtube_links.txt' \n",
    "youtube_links = [l[0] for l in read_csv(file_links, header=None).values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping initializing\n",
    "for url in youtube_links:\n",
    "    # open chrome\n",
    "    file_chromedriver = 'needed_files\\chromedriver.exe'\n",
    "    driver = webdriver.Chrome(service=Service(file_chromedriver))\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(10)\n",
    "\n",
    "    # collect info\n",
    "    title = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/h1/yt-formatted-string')[0].text\n",
    "    views = driver.find_elements(By.XPATH,'//*[@id=\"count\"]/ytd-video-view-count-renderer/span[1]')[0].text\n",
    "    likes = driver.find_elements(By.XPATH, '//*[@id=\"text\"]')[2].text\n",
    "\n",
    "    # number of comments\n",
    "    driver.execute_script('window.scrollTo(0,390);')\n",
    "    time.sleep(2)  # time for loading the video\n",
    "    n_comments = int(driver.find_elements(By.XPATH, '//*[@id=\"count\"]/yt-formatted-string/span[1]')[0].text.replace('.',''))\n",
    "\n",
    "    # scroll down to load comments\n",
    "    total_comments = False\n",
    "    i = 390; k = 4000\n",
    "    while not total_comments:\n",
    "        for j in range(i, k, 500):\n",
    "            driver.execute_script('window.scrollTo({},{});'.format(i,j))\n",
    "            time.sleep(2)\n",
    "\n",
    "        # Extract comments info\n",
    "        comments_info = driver.find_elements(By.CSS_SELECTOR,'#contents #comment')\n",
    "\n",
    "        # Extract comments\n",
    "        comments = [c.text for c in driver.find_elements(By.XPATH, '//*[@id=\"content-text\"]')]\n",
    "        commentsLikes = [upvote.text for upvote in driver.find_elements(By.XPATH, '//*[@id=\"vote-count-middle\"]')]\n",
    "\n",
    "        # Find comments with replies\n",
    "        n_replie = 0\n",
    "        replies = driver.find_elements(By.XPATH,'//*[@id=\"replies\"]')\n",
    "        for r in replies:\n",
    "            if r.text != '':\n",
    "                try:\n",
    "                    n_replie = n_replie + int(r.text.split(' ')[1]) # if there is an error it is because it is a single answer. There is no \"1 answer\"\n",
    "                except:\n",
    "                    n_replie = n_replie + 1\n",
    "\n",
    "        # percentage of comments obtained\n",
    "        commentPercentObtained = (len(comments)+n_replie)/n_comments\n",
    "        \n",
    "        if commentPercentObtained >= 0.9:\n",
    "            total_comments = True \n",
    "        else:\n",
    "            i = j; k = 2 * j\n",
    "\n",
    "    # Close the googledriver\n",
    "    driver.close()\n",
    "\n",
    "    # fill the dict\n",
    "    for i in range(0,len(comments),1):\n",
    "        youtube_info['url'] = url\n",
    "        youtube_info['title'] = title\n",
    "        youtube_info['views'] = views\n",
    "        youtube_info['likes'] = likes\n",
    "        youtube_info['comments'] = comments[i]\n",
    "        youtube_info['comments_likes'] = commentsLikes[i]\n",
    "\n",
    "        # write results in csv file\n",
    "        writer.writerow(youtube_info.values())\n",
    "\n",
    "csv_file.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d48975cc0f0925764d614904bdf2ceead9ed3f84b9ab9fe3059c1b950a52fa38"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
